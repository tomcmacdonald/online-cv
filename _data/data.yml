#
# Be aware that even a small syntax error here can lead to failures in output.
#

sidebar:
  position: left # position of the sidebar : left or right
  about: False # set to False or comment line if you want to remove the "how to use?" in the sidebar
  education: True # set to False if you want education in main section instead of in sidebar

  # Profile information
  name: Tom C. MacDonald
  tagline: Data Engineer
  avatar: profile.png #place a 100x100 picture inside /assets/images/ folder and provide the name of the file below

  # Sidebar links
  email: tom.c.macdonald@gmail.com
  phone: (347) 545-1698
  timezone: America/New_York # Enter your timezone, e.g., America/Havana, Africa/Casablanca, America/North_Dakota/Center
  citizenship:
  website: https://www.tomcmacdonald.com/ # Include the full website URL, including "http://" or "https://".
  linkedin: tom-macdonald-ab131866
  xing: 
  github: tomcmacdonald
  telegram: # add your nickname without '@' sign
  gitlab:
  bitbucket:
  bluesky: # Specify your full Bluesky handle
  twitter: 
  stack-overflow: # Number/Username, e.g. 123456/alandoe
  codewars:
  goodreads: # Number-Username, e.g. 123456-alandoe
  mastodon: # Please include your full Mastodon link here.
  hackerrank: # Please provide your HackerRank username.
  leetcode: # Please provide your LeetCode username.
  pdf: # Add a PDF link here if you want to include a PDF custom version in your resume.

  languages:
    title: Languages
    info:
    - idiom: English

  interests:
    title: Interests
    info:
    - item: Hiking
    - item: Running
    - item: Weight Lifting

education:
  title: Education
  info:
  - degree: BA in Applied Mathemtics 
    university: CUNY Queens College
  - degree: BA in Economics
    university: SUNY Stony Brook

experiences:
  title: Experiences
  info:
  - role: Senior Data Engineer
    time: June 2024 - Present
    company: New York Blood Center
    details: |
      - Developed pipelines in Azure Data Factory and Databricks
      - Contributed to modeling design work
      - Spoke with and managed expectations from stakeholders
  - role: Data Engineer
    time: January 2022 to June 2024
    company: Crowdstreet
    details: |
      - Created custom data extractors using Python in Singer.io framework
      - Deployed pipelines using Meltano using AWS Elastic Container Service
      - Implemented extractions using AWS Lambda
      - Created pipeline from data warehouse to Salesforce and HubSpot
      - Modeled data from several different sources with dbt
      - Collaborated with data scientists to train machine learning models using AWS Sagemaker
      - Containerized machine learning models in Docker
      - Deployed models in AWS Elastic Container Service
      - Deployed AWS infrastructure with Terraform
      - Managed junior data engineer
      - Collaborated with data analysts
      - Administered and maintained Looker project and dashboards
      - Collaborated with stakeholders from executives in several departments to meet their data needs
      - Administered Snowflake data warehouse and implemented role-based security to protect personal identifiable information
      - Created Azure Data Factory pipelines and dataflows
      - Created Databricks Notebooks using Apache Spark for transformations in Azure Data Factory
      - Created dashboards in Power BI
      - Created documentation in Atlassian Confluence
      - Created tickets in Atlassian JIRA
  - role: Senior Software Engineer
    time: August 2020 to January 2022
    company: Blackhawk Network
    details: |
      - Implemented OIDC authentication for Django
      - Implemented OAuth2 server-to-server authentication between microservices using Django and Flask
      - Contributed to Django, Flask, and React projects
      - Monitored application using Sentry
      - Monitored infrastructure using AWS CloudWatch
      - Developed a rule engine to automatically tag orders
      - Collaborated closely with stakeholders when implementing features
      - Contributed to architectural design decisions
      - Created documentation in Atlassian Confluence
      - Created tickets in Atlassian JIRA
  - role: Software Engineer
    time: December 2019 to August 2020
    company: Garmin
    details: |
      - Managed legacy batch processes which rendered map tiles in Azure
      - Developed tooling in Python, C#, and PowerShell to optimize batch processes
      - Developed Python application to convert proprietary geospatial format to an open format using numpy
      - Developed web scrapers to help analysts download raw geospatial data using Selenium and Scrapy
      - Created documentation for these applications
  - role: Software Engineer in Test
    time: March 2019 to August 2020
    company: dv01
    details: |
      - Managed legacy batch processes which rendered map tiles in Azure
      - Developed tooling in Python, C#, and PowerShell to optimize batch processes
      - Developed Python application to convert proprietary geospatial format to an open format using numpy
      - Developed web scrapers to help analysts download raw geospatial data using Selenium and Scrapy
      - Created documentation for these applications
  - role: Programmer/Analyst
    time: June 2016 to March 2019
    company: New York City Department of Finance
    details: |
      - Developed web scraper application for data collection from government websites
      - Built internal web map application using React, Leaflet, and Flask to help property accessors
      - Used SAS to maintain legacy reports
      - Developed tooling in Python to run SAS programs on IBM OS/360 mainframe using FTP
      - Collaborated with stakeholders on database schema development
      - Responded to adhoc requests for data from various departments
  - role: GIS Engineer
    time: April 2014 to June 2016
    company: Winick Realty
    details: |
      - Designed and maintained geospatial databases to used in analysis
      - Scrapped various retailer websites using Scrapy to find store locations
      - Scrapped third-party API's using Scrapy to find data to help develop maps and charts
      - Stored data in PostGIS geodatabase
      - Created maps with Adobe Illustrator with Avenza and PostGIS to be used for marketing materials
      - Created charts with Python, ggplot2 and matplotlib to be used for marketing materials
      - Responded to adhoc requests for data and maps
      - Built internal web map application using Flask and jQuery to organize listings
      - Collaborated with real estate brokers on marketing strategies

skills:
  title: Skills &amp; Proficiency

  toolset:
  - name: Python
    level: 98%

  - name: SQL
    level: 98%

  - name: Databricks
    level: 85%

  - name: R
    level: 85%

  - name: Java
    level: 70%

  - name: C#
    level: 60%
